{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51a1c3e",
   "metadata": {},
   "source": [
    "### 메타 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99415faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import poisson, loguniform\n",
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "from sklearn.neural_network import MLPRegressor as MLPR\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.stats import norm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e38c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_features(X, y):\n",
    "    m1, m2 = X.shape # 샘플 개수, 특징 개수\n",
    "    y_vc = y.value_counts() # 라벨 분포\n",
    "    m3 = y_vc.iloc[0] / y_vc.iloc[-1] # 클래스 불균형 비율\n",
    "    m4 = m2 / m1 # 샘플 대비 특징 비율\n",
    "    m5 = sum(X.dtypes == float) / m2 # 정수형 특징 비율\n",
    "    m6 = sum(X.dtypes == int) / m2 # 실수형 특징 비율\n",
    "    m7 = (X.max() - X.min()).max() # 특징별 범위의 최댓값\n",
    "    m8 = (X.max() - X.min()).min() # 특징별 범위의 최솟값\n",
    "    m9 = sum(X.min() > 0) / m2 # 모든 값이 양수인 비율\n",
    "    \n",
    "    return [m1, m2, m3, m4, m5, m6, m7, m8, m9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fcc2fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling():\n",
    "    h1 = poisson(15).rvs()\n",
    "    h2 = poisson(3).rvs()\n",
    "    h3 = poisson(2).rvs() if h2 > 0 else 0\n",
    "    h4 = poisson(1).rvs() if h3 > 0 else 0\n",
    "    max_iter = int(loguniform(100, 10000).rvs())\n",
    "    learning_rate_init = loguniform(0.0001, 0.1).rvs()\n",
    "    s1 = np.random.choice([0, 1])\n",
    "    s2 = np.random.choice([0, 1])\n",
    "    s3 = np.random.choice([0, 1]) if s2 == 0 else 0\n",
    "    \n",
    "    return [h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb981c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, X, y, s1, s2, s3):\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 2022)\n",
    "    # 데이터 타입 변경 (pandas -> numpy)\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "    \n",
    "    # 모델 학습\n",
    "    score = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if s1 == 1:\n",
    "            scaler = MinMaxScaler().fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        \n",
    "        if s2 == 1:\n",
    "            X_train, y_train = SMOTE(k_neighbors = 3,\n",
    "                                     random_state=2022).fit_resample(X_train, y_train)\n",
    "        elif s3 == 1:\n",
    "            X_train, y_train = NearMiss().fit_resample(X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score += f1_score(y_test, y_pred) / 5\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d14701",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file_name_list = [\n",
    "    \"shuttle-c2-vs-c4\",\n",
    "    \"iris0\",\n",
    "    \"glass-0-1-6_vs_5\",\n",
    "    \"glass-0-1-6_vs_2\",\n",
    "    \"sonar\",\n",
    "    \"glass0\",\n",
    "    \"glass-0-1-2-3_vs_4-5-6\",\n",
    "    \"glass1\",\n",
    "    \"glass2\",\n",
    "    \"glass5\",\n",
    "    \"glass6\",\n",
    "    \"new-thyroid1\",\n",
    "    \"ecoli-0_vs_1\",\n",
    "    \"spectfheart\",\n",
    "    \"heart\",\n",
    "    \"haberman\",\n",
    "    \"bupa\",\n",
    "    \"ionosphere\",\n",
    "    \"monk-2\",\n",
    "    \"page-blocks-1-3_vs_4\",\n",
    "    \"wdbc\",\n",
    "    \"vehicle0\",\n",
    "    \"vehicle2\",\n",
    "    \"vehicle3\",\n",
    "    \"yeast-1-2-8-9_vs_7\",\n",
    "    \"vowel0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b62cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_list = []\n",
    "for file_name in meta_file_name_list:\n",
    "    df = pd.read_csv(\"../../data/classification/{}.csv\".format(file_name))\n",
    "    X = df.drop('y', axis = 1)\n",
    "    y = df['y']\n",
    "    meta_features = extract_meta_features(X, y)\n",
    "    meta_data_list.append((X, y, meta_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df30f54",
   "metadata": {},
   "source": [
    "#### 메타 모델 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05cd76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X = []\n",
    "meta_y = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    idx = np.random.choice(range(len(meta_file_name_list)))\n",
    "    X, y, meta_features = meta_data_list[idx]\n",
    "    h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3 = sampling()\n",
    "    \n",
    "    if h2 == 0:\n",
    "        hidden_layer_sizes = (h1, )\n",
    "    elif h3 == 0:\n",
    "        hidden_layer_sizes = (h1, h2)\n",
    "    elif h4 == 0:\n",
    "        hidden_layer_sizes = (h1, h2, h3)\n",
    "    else:\n",
    "        hidden_layer_sizes = (h1, h2, h3, h4)\n",
    "    \n",
    "    model = MLPC(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                max_iter = max_iter,\n",
    "                learning_rate_init = learning_rate_init,\n",
    "                random_state = 2022)\n",
    "    \n",
    "    score = model_test(model, X, y, s1, s2, s3)\n",
    "    record = [h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3]\n",
    "    record += meta_features\n",
    "    \n",
    "    meta_X.append(record)\n",
    "    meta_y.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a3e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X_cols = [\"h1\", \"h2\", \"h3\", \"h4\",\n",
    "               \"max_iter\", \"learning_rate_init\",\n",
    "               \"s1\", \"s2\", \"s3\",\n",
    "               \"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"m7\", \"m8\", \"m9\"]\n",
    "meta_X = pd.DataFrame(meta_X, columns = meta_X_cols)\n",
    "meta_y = pd.Series(meta_y)\n",
    "meta_y.name = \"y\"\n",
    "meta_df = pd.concat([meta_X, meta_y], axis = 1)\n",
    "meta_df.to_csv(\"MyAutoML3_메타모델_학습데이터.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0cab3",
   "metadata": {},
   "source": [
    "#### 메타 모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "819ceb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(18, 5, 2, 1),\n",
       "             learning_rate_init=0.0007337677668986755, max_iter=250,\n",
       "             random_state=2022)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = np.inf\n",
    "for _ in range(1000):\n",
    "    h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3 = sampling()\n",
    "    if h2 == 0:\n",
    "        hidden_layer_sizes = (h1,)\n",
    "    elif h3 == 0:\n",
    "        hidden_layer_sizes = (h1, h2)\n",
    "    elif h4 == 0:\n",
    "        hidden_layer_sizes = (h1, h2, h3)\n",
    "    else:\n",
    "        hidden_layer_sizes = (h1, h2, h3, h4)\n",
    "    model = MLPR(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        max_iter=max_iter,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        random_state=2022,\n",
    "    )\n",
    "\n",
    "    score = -cross_val_score(\n",
    "        model, meta_X, meta_y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    "    ).mean()\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "best_model.fit(meta_X, meta_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8123a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MyAutoML3_meta_model.pckl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690d217",
   "metadata": {},
   "source": [
    "### 시스템 구현 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ce5551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoML3:\n",
    "    ## 생성자\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed=None,\n",
    "        cv=5,\n",
    "        scoring=\"f1\",\n",
    "        summarize_scoring=\"mean\",\n",
    "        num_iter=1000,\n",
    "        num_candidate=100,\n",
    "        num_init=10,\n",
    "        num_sample=1,\n",
    "    ):\n",
    "\n",
    "        # self.seed 정의\n",
    "        if (type(seed) != int) and (seed is not None):\n",
    "            raise ValueError(\"seed는 int형 혹은 None이어야 합니다.\")\n",
    "        self.seed = seed\n",
    "\n",
    "        # self.cv 정의\n",
    "        if type(cv) != int:\n",
    "            raise ValueError(\"cv는 int형이어야 합니다.\")\n",
    "        if cv < 2:\n",
    "            raise ValueError(\"cv는 2보다는 커야 합니다.\")\n",
    "        self.cv = cv\n",
    "\n",
    "        # self.scoring 정의\n",
    "        scoring_dict = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"precision\": precision_score,\n",
    "            \"recall\": recall_score,\n",
    "            \"f1\": f1_score,\n",
    "        }\n",
    "\n",
    "        if scoring not in scoring_dict.keys():\n",
    "            msg = \"scoring은 {}중 하나여야 합니다.\".format(scoring_dict.keys())\n",
    "            raise ValueError(msg)\n",
    "        self.scoring = scoring_dict[scoring]\n",
    "\n",
    "        # self.summarize_scoring 정의\n",
    "        summarize_scoring_dict = {\"mean\": np.mean, \"max\": np.max, \"min\": np.min}\n",
    "\n",
    "        if summarize_scoring not in [\"mean\", \"max\", \"min\"]:\n",
    "            msg = \"summarize_scoring는 {'mean', 'max', 'min'}중 하나여야 합니다.\"\n",
    "            raise ValueError(msg)\n",
    "        self.summarize_scoring = summarize_scoring_dict[summarize_scoring]\n",
    "\n",
    "        # self.num_iter 정의\n",
    "        if type(num_iter) != int:\n",
    "            raise ValueError(\"num_iter는 int 자료형이어야 합니다.\")\n",
    "        elif num_iter <= 0:\n",
    "            raise ValueError(\"num_iter는 0보다 커야 합니다.\")\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "        # self.num_candidate 정의\n",
    "        if type(num_candidate) != int:\n",
    "            raise ValueError(\"num_candidate는 int 자료형이어야 합니다.\")\n",
    "        elif num_candidate <= 0:\n",
    "            raise ValueError(\"num_candidate는 0보다 커야 합니다.\")\n",
    "        self.num_candidate = num_candidate\n",
    "\n",
    "        # self.num_init 정의\n",
    "        if type(num_init) != int:\n",
    "            raise ValueError(\"num_init은 int 자료형이어야 합니다.\")\n",
    "        elif num_init <= 0:\n",
    "            raise ValueError(\"num_init은 0보다 커야 합니다.\")\n",
    "        self.num_init = num_init\n",
    "\n",
    "        # self.num_sample 정의\n",
    "        if type(num_sample) != int:\n",
    "            raise ValueError(\"num_sample은 int 자료형이어야 합니다.\")\n",
    "        elif num_sample <= 0:\n",
    "            raise ValueError(\"num_sample은 0보다 커야 합니다.\")\n",
    "        elif num_sample > num_candidate:\n",
    "            raise ValueError(\"num_sample은 num_candidate보다 커야 합니다.\")\n",
    "        self.num_sample = num_sample\n",
    "\n",
    "        # self.meta_model 정의\n",
    "        with open(\"MyAutoML3_meta_model.pckl\", \"rb\") as f:\n",
    "            self.meta_model = pickle.load(f)\n",
    "\n",
    "    ## _extract_meta_features 메서드\n",
    "    def _extract_meta_features(self, X, y):\n",
    "        m1, m2 = X.shape  # 샘플 개수, 특징 개수\n",
    "        y_vc = y.value_counts()  # 라벨 분포\n",
    "        m3 = y_vc.iloc[0] / y_vc.iloc[-1]  # 클래스 불균형 비율\n",
    "        m4 = m2 / m1  # 샘플 대비 특징 비율\n",
    "        m5 = sum(X.dtypes == float) / m2  # 정수형 특징 비율\n",
    "        m6 = sum(X.dtypes == int) / m2  # 실수형 특징 비율\n",
    "        m7 = (X.max() - X.min()).max()  # 특징별 범위의 최댓값\n",
    "        m8 = (X.max() - X.min()).min()  # 특징별 범위의 최솟값\n",
    "        m9 = sum(X.min() > 0) / m2  # 모든 값이 양수인 비율\n",
    "\n",
    "        return [m1, m2, m3, m4, m5, m6, m7, m8, m9]\n",
    "\n",
    "    ## _sampling 메서드\n",
    "    def _sampling(self):\n",
    "        h1 = poisson(15).rvs()\n",
    "        h2 = poisson(3).rvs()\n",
    "        h3 = poisson(2).rvs() if h2 > 0 else 0\n",
    "        h4 = poisson(1).rvs() if h3 > 0 else 0\n",
    "        max_iter = int(loguniform(100, 10000).rvs())\n",
    "        learning_rate_init = loguniform(0.0001, 0.1).rvs()\n",
    "        s1 = np.random.choice([0, 1])\n",
    "        s2 = np.random.choice([0, 1])\n",
    "        s3 = np.random.choice([0, 1]) if s2 == 0 else 0 \n",
    "\n",
    "        return [h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3]\n",
    "\n",
    "    ## _solution_evaluate 메서드\n",
    "    def _solution_evaluate(self, solution, X, y):\n",
    "        h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3 = solution\n",
    "        h1, h2, h3, h4, max_iter = tuple(map(int, (h1, h2, h3, h4, max_iter)))\n",
    "        if h2 == 0:\n",
    "            hidden_layer_sizes = (h1,)\n",
    "        elif h3 == 0:\n",
    "            hidden_layer_sizes = (h1, h2)\n",
    "        elif h4 == 0:\n",
    "            hidden_layer_sizes = (h1, h2, h3)\n",
    "        else:\n",
    "            hidden_layer_sizes = (h1, h2, h3, h4)\n",
    "        model = MLPC(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            max_iter=max_iter,\n",
    "            learning_rate_init=learning_rate_init,\n",
    "            random_state=2022,\n",
    "        )\n",
    "\n",
    "        fold_score_list = []\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if s1 == 1:\n",
    "                scaler = MinMaxScaler().fit(X_train)\n",
    "                X_train = scaler.transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "            if s2 == 1:\n",
    "                X_train, y_train = SMOTE(k_neighbors=3, random_state=2022).fit_resample(\n",
    "                    X_train, y_train\n",
    "                )\n",
    "            elif s3 == 1:\n",
    "                X_train, y_train = NearMiss().fit_resample(X_train, y_train)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            fold_score = self.scoring(y_test, y_pred)\n",
    "            fold_score_list.append(fold_score)\n",
    "        score = self.summarize_scoring(fold_score_list)\n",
    "        return score\n",
    "    \n",
    "    ## _EI 메서드\n",
    "    def _EI(self, X_new, surrogate_model, best_mu, e=0.01):\n",
    "        mu, sigma = surrogate_model.predict(X_new, return_std=True)\n",
    "        z = np.zeros(len(X_new))\n",
    "        z[sigma > 0] = ((mu - best_mu - e) / sigma)[sigma > 0]\n",
    "        return (mu - best_mu - e) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "\n",
    "    ## fit 메서드\n",
    "    def fit(self, X, y):\n",
    "        # X, y 포맷 변경\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        elif isinstance(X, list) or isinstance(X, tuple):\n",
    "            X = np.array(X)\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        elif isinstance(y, list) or isinstance(y, tuple):\n",
    "            y = np.array(y)\n",
    "        # 베이지안 최적화 시작\n",
    "        meta_features = self._extract_meta_features(pd.DataFrame(X), pd.Series(y))\n",
    "        candidate_list = []\n",
    "        for _ in range(self.num_candidate):\n",
    "            candidate = meta_features + self._sampling()\n",
    "            candidate_list.append(candidate)\n",
    "        candidate_score_list = self.meta_model.predict(candidate_list)\n",
    "        top_num_init_idx_list = (-candidate_score_list).argsort()[:self.num_init]\n",
    "\n",
    "        GP_X = []\n",
    "        GP_y = []\n",
    "        for idx in top_num_init_idx_list:\n",
    "            gp_x = candidate_list[idx][len(meta_features) :]\n",
    "            gp_y = self._solution_evaluate(gp_x, X, y)\n",
    "\n",
    "            GP_X.append(gp_x)\n",
    "            GP_y.append(gp_y)\n",
    "        surrogate_model = GPR(kernel=Matern(), random_state=2022).fit(GP_X, GP_y)\n",
    "\n",
    "        best_mu = max(surrogate_model.predict(GP_X))\n",
    "        for _ in range(self.num_iter - 1):\n",
    "            candidate_list = np.array(\n",
    "                [self._sampling() for _ in range(self.num_candidate)]\n",
    "            )\n",
    "            candidate_score_list = self._EI(candidate_list, surrogate_model, best_mu)\n",
    "\n",
    "            new_GP_X = list(\n",
    "                candidate_list[(-candidate_score_list).argsort()[: self.num_sample]]\n",
    "            )\n",
    "            new_GP_y = [\n",
    "                self._solution_evaluate(new_gp_x, X, y) for new_gp_x in new_GP_X\n",
    "            ]\n",
    "\n",
    "            GP_X += new_GP_X\n",
    "            GP_y += new_GP_y\n",
    "            \n",
    "            current_best_mu = max(surrogate_model.predict(new_GP_X))\n",
    "            if current_best_mu > best_mu: \n",
    "                best_mu = current_best_mu\n",
    "            surrogate_model = GPR(kernel=Matern(), random_state=2022).fit(GP_X, GP_y)\n",
    "            \n",
    "        self.leaderboard = pd.DataFrame(\n",
    "            GP_X,\n",
    "            columns=[\n",
    "                \"h1\",\n",
    "                \"h2\",\n",
    "                \"h3\",\n",
    "                \"h4\",\n",
    "                \"max_iter\",\n",
    "                \"learning_rate_init\",\n",
    "                \"s1\",\n",
    "                \"s2\",\n",
    "                \"s3\",\n",
    "            ],\n",
    "        )\n",
    "        self.leaderboard[\"점수\"] = GP_y\n",
    "        \n",
    "        # 최종 모델 선정 및 학습\n",
    "        h1, h2, h3, h4, max_iter, learning_rate_init, s1, s2, s3 = GP_X[np.array(GP_y).argmax()]\n",
    "        h1, h2, h3, h4, max_iter = tuple(map(int, (h1, h2, h3, h4, max_iter)))\n",
    "        if h2 == 0:\n",
    "            hidden_layer_sizes = (h1,)\n",
    "        elif h3 == 0:\n",
    "            hidden_layer_sizes = (h1, h2)\n",
    "        elif h4 == 0:\n",
    "            hidden_layer_sizes = (h1, h2, h3)\n",
    "        else:\n",
    "            hidden_layer_sizes = (h1, h2, h3, h4)\n",
    "        best_model = MLPC(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            max_iter=max_iter,\n",
    "            learning_rate_init=learning_rate_init,\n",
    "            random_state=2022,\n",
    "        )\n",
    "        \n",
    "        if s1 == 1:\n",
    "            scaler = MinMaxScaler().fit(X)\n",
    "            X = scaler.transform(X)\n",
    "        if s2 == 1:\n",
    "            X, y = SMOTE(k_neighbors=3, random_state=2022).fit_resample(X, y)\n",
    "        elif s3 == 1:\n",
    "            X, y = NearMiss().fit_resample(X, y)\n",
    "        \n",
    "        self.model = best_model.fit(X, y)\n",
    "\n",
    "    ## predict 메서드\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)   \n",
    "        \n",
    "    ## show_leaderboard 메서드\n",
    "    def show_leaderboard(self):\n",
    "        return self.leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb221a",
   "metadata": {},
   "source": [
    "### 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "58df3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"../../data/classification/glass4.csv\")\n",
    "X = df.drop('y', axis = 1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21988f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = MyAutoML3(scoring = \"accuracy\")\n",
    "aml.fit(X, y)\n",
    "result = aml.show_leaderboard()\n",
    "display(result.sort_values(by = \"점수\", ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"../../data/classification/vehicle1.csv\")\n",
    "X = df.drop('y', axis = 1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = MyAutoML3(scoring = \"f1\", num_iter = 100)\n",
    "aml.fit(X, y)\n",
    "result = aml.show_leaderboard()\n",
    "display(result.sort_values(by = \"점수\", ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cdf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
